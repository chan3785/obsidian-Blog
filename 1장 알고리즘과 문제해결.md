
### 날짜 : 2024-04-24 22:23

### 주제: #복잡도 

---
### 메모: 
## Time Complexity (시간 복잡도)
알고리즘을 실행시켜 완료하는데 걸리는 시간
$T_a$ = $T_c$ + $T_e$ 
$T_c$ : 컴파일 시간
$T_e$ : 실행 시간
- 단위 명령문 하나를 실행하는데 걸리는 시간
- 실행 빈도수 (frequency count)
## Space Complexity (공간 복잡도)
알고리즘을 실행시켜 완료하는데 필요한 총 저장 공간
$S_a$ = $S_c$ + $S_e$ 
$S_c$ : 고정 공간
- 명령어 공간, 단순 변수, 복합 데이타 구조와 변수, 상수
$S_e$ : 가변 공간
- 크기가 변하는 데이터 구조와 변수들이 필요로 하는 저장 공간
- 런타임 스택 (runtime stack)을 위한 저장 공간
## Asymptotic Analysis (점근선 분석)
실행시간이 *"grows proportionally to $f(n)$"* 한다는 사실 만으로 충분
실제 실행 시간은 c (constant factor) * $f(n)$이 된다.
어떤 알고리즘의 worst-case가 $g(N) = 60N^{2} + 5N + 1$ 이면 
![[Pasted image 20240424225544.png]]
$g(N) = {\Theta}(N^{2})$ : $g(N)$의 growth rate는 $N^2$의 growth rate와 같아진다.
최고차항 (Dominant Factor)이 지배한다. 

## 복잡도 함수 카테고리

$\Theta$ (1) : constant complexity 
- 입력 자료수에 무관 -> 뭐든 한번에 실행
- 해슁
  
$\Theta$ ($log$$log$ $n$)

$\Theta$ ($log$ $n$): logarithmic complexity
- divide & conquer
- 이진 검색 BST
  
$\Theta$ ($n$) : linear complexity
- scan search
  
$\Theta$ ($n$ $log$ $n$)
- merge sort, quick sort ...
  
$\Theta$ ($n^k$) ($k$ $\geq$ 1)
- $\Theta(n^2)$ : quadratic complexity
	 - 이중 loop, Insertion sort, Selection sort ...
- $\Theta(n^3)$ : cubic complexity 
	 - 삼중 loop, 행렬의 곱셈

여기까지가 polynomial time

$\Theta(2^n)$ : exponential complexity
- Knapsack problem, Fibonacci, Hanoi…

$2^{n}$ 그 다음이 $n!$ 
exponential time algorithm 
피보나치, 하노이 등등..

![[Pasted image 20240424231347.png]]

## Big $O$ 표기법
정의: 점근적 상한(Asymptotic Upper Bound)
- 주어진 복잡도 함수 $f(n)$ 에 대해서 $g(n)\ {\in}\ O(f(n))$이면 다음을 만족한다.
- $n \geq N$ 인 모든 정수 $n$에 대해서 $g(n) \leq c \times f(n)$이 성립하는 실수 $c > 0$와 음이 아닌 정수 N이 존재한다. 

$g(n)\ {\in}\ O(f(n))$ 읽는 방법: 
- $g(n)$은 $f(n)$의 Big O
우리가 구한 $T_{n}$이 $g(n)$이다.

![[Pasted image 20240425075102.png]]

1. $T(n) \leq c \times f(n)$
2. 식을 만족하는 c와 n0 잘 고르기
3. c를 찾으면 n0에 값을 계속 대입해서 검증을 해야 한다

$N (= n_{0})$이상부터는 항상 $c\cdot f(n)$밑에 있게 된다.
 
예) 어떤 함수 $g(n)$이 $O(n^{2})$에 속한다는 말은,
$g(n)$은 궁극에 가서는 (어떤 임의의 $N$보다 큰 값에 대해서는) 어떤 2차 함수 $c \cdot n^{2}$보다는 작은 값을 가지게 된다는 것을 뜻한다. 
= $g(n)$은 어떤 2차 함수 $c \cdot n^{2}$ 보다는 궁극적으로 좋다고 할 수 있다.

여기서 끝나면 안되고 검증을 해야 한다.
$T(n)$이 사인처럼 웨이브가 있으면 초과가 될 수도 있다.
마지막으로 교차된 교점을 기준으로 해야 한다.
##### 어떤 알고리즘의 시간복잡도가 $O(f(n))$이라면 
- 입력의 크기 $n$에 대해서 알고리즘의 수행시간은 **아무리 늦어도** $f(n)$은 된다. ($f(n)$이 상한이다.)
- 수행시간이 $f(n)$보다 더 느릴 수는 없다는 말이다.
= Worst-case일 때, 이 정도 시간이면 된다.

##### Tight upper bound
길어야 $N$시간이면 되는 알고리즘은 $N^{2}$도 $N^{3}$도 만족하는 게 당연하다.
- 알고리즘의 특성을 표현하려면 Tight upper bound를 사용해야 함.
= Say “$2n$ is $O(n)$” instead of “$2n$ is $O(n^{2})$”

##### Use the simplest expression of the class
= Say “$3n + 5$ is $O(n)$” instead of “$3n + 5$ is $O(3n)$”

###### 예) $n2+10n\ {\in}\ O(n^2)$ ?
- 1) $n \geq 10$인 모든 정수 $n$에 대해서 $n^2+10n \leq 2n^2$ 이 성립한다. 그러므로, $c = 2, n_0 = 10$을 선택하면, “$Big \ O$”의 정의에 의해서 $n2+10n\ {\in}\ O(n^2)$이라고 결론 지을 수 있다.
###### $2n^{2}$과 $n^{2} + 10n$의 비교
![[Pasted image 20240425090745.png]]

## $\Omega$ 표기법
점근적 하한
##### 어떤 알고리즘의 시간복잡도가 $\Omega(f(n))$이라면 
- 입력의 크기 $n$에 대해서 알고리즘의 수행시간은 **아무리 빨라도** $f(n)$은 된다. *($f(n)$이 하한이다.)*
- 수행시간이 $f(n)$보다 더 빠를 수는 없다는 말이다.
= Best-case일 때, **최소한 이만한 시간은 걸린다.**
* 모든 정렬 알고리즘은 $\Omega(N)$. $N$개의 데이터를 정렬하는데 $N$개 모두를 읽지않고 정렬을 완료할 수는 없기 때문.


## $\Theta$ 표기법
정의: Asymptotic Tight Bound
- 복잡도 함수 $f(n)$에 대해서 $\Theta(f(n))=O(f(n)) \cap \Omega(f(n))$ 
- $\Theta(f(n))$은 다음을 만족하는 복잡도 함수 $g(n)$의 집합이다.

= $n \geq n_{0}$ 인 모든 정수 $n$에 대해서 $c \times f(n) \leq g(n) \leq d \times f(n)$ 이 성립하는 실수 $c > 0$와 $d > 0$, 음이 아닌 정수 $N$이 존재한다..

### 출처(참고문헌)
-

### 연결문서
-