
### 날짜 : 2024-04-24 22:23

### 주제: #복잡도 

---
### 메모: 
## Time Complexity (시간 복잡도)
알고리즘을 실행시켜 완료하는데 걸리는 시간
$T_a$ = $T_c$ + $T_e$ 
$T_c$ : 컴파일 시간
$T_e$ : 실행 시간
- 단위 명령문 하나를 실행하는데 걸리는 시간
- 실행 빈도수 (frequency count)
## Space Complexity (공간 복잡도)
알고리즘을 실행시켜 완료하는데 필요한 총 저장 공간
$S_a$ = $S_c$ + $S_e$ 
$S_c$ : 고정 공간
- 명령어 공간, 단순 변수, 복합 데이타 구조와 변수, 상수
$S_e$ : 가변 공간
- 크기가 변하는 데이터 구조와 변수들이 필요로 하는 저장 공간
- 런타임 스택 (runtime stack)을 위한 저장 공간
## Asymptotic Analysis (점근선 분석)
실행시간이 *"grows proportionally to $f(n)$"* 한다는 사실 만으로 충분
실제 실행 시간은 c (constant factor) * $f(n)$이 된다.
어떤 알고리즘의 worst-case가 $g(N) = 60N^{2} + 5N + 1$ 이면 
![[Pasted image 20240424225544.png]]
$g(N) = {\Theta}(N^{2})$ : $g(N)$의 growth rate는 $N^2$의 growth rate와 같아진다.
최고차항 (Dominant Factor)이 지배한다. 

## 복잡도 함수 카테고리

$\Theta$ (1) : constant complexity 
- 입력 자료수에 무관 -> 뭐든 한번에 실행
- 해슁
  
$\Theta$ ($log$$log$ $n$)

$\Theta$ ($log$ $n$): logarithmic complexity
- divide & conquer
- 이진 검색 BST
  
$\Theta$ ($n$) : linear complexity
- scan search
  
$\Theta$ ($n\log$ $n$)
- merge sort, quick sort ...
  
$\Theta$ ($n^k$) ($k$ $\geq$ 1)
- $\Theta(n^2)$ : quadratic complexity
	 - 이중 loop, Insertion sort, Selection sort ...
- $\Theta(n^3)$ : cubic complexity 
	 - 삼중 loop, 행렬의 곱셈

여기까지가 polynomial time

$\Theta(2^n)$ : exponential complexity
- Knapsack problem, Fibonacci, Hanoi…

$2^{n}$ 그 다음이 $n!$ 
exponential time algorithm 
피보나치, 하노이 등등..

![[Pasted image 20240424231347.png]]

## Big $O$ 표기법
정의: 점근적 상한(Asymptotic Upper Bound)
- 주어진 복잡도 함수 $f(n)$ 에 대해서 $g(n)\ {\in}\ O(f(n))$이면 다음을 만족한다.
- $n \geq N$ 인 모든 정수 $n$에 대해서 $g(n) \leq c \times f(n)$이 성립하는 실수 $c > 0$와 음이 아닌 정수 N이 존재한다. 

$g(n)\ {\in}\ O(f(n))$ 읽는 방법: 
- $g(n)$은 $f(n)$의 Big O
우리가 구한 $T_{n}$이 $g(n)$이다.

![[Pasted image 20240425075102.png]]

#### 알고리즘 복잡도 식
1. $T(n) \leq c \times f(n)$
2. 식을 만족하는 c와 n0 잘 고르기
3. c를 찾으면 n0에 값을 계속 대입해서 검증을 해야 한다

$N (= n_{0})$이상부터는 항상 $c\cdot f(n)$밑에 있게 된다.
 
예) 어떤 함수 $g(n)$이 $O(n^{2})$에 속한다는 말은,
$g(n)$은 궁극에 가서는 (어떤 임의의 $N$보다 큰 값에 대해서는) 어떤 2차 함수 $c \cdot n^{2}$보다는 작은 값을 가지게 된다는 것을 뜻한다. 
= $g(n)$은 어떤 2차 함수 $c \cdot n^{2}$ 보다는 궁극적으로 좋다고 할 수 있다.

여기서 끝나면 안되고 검증을 해야 한다.
$T(n)$이 사인처럼 웨이브가 있으면 초과가 될 수도 있다.
마지막으로 교차된 교점을 기준으로 해야 한다.
##### 어떤 알고리즘의 시간복잡도가 $O(f(n))$이라면 
- 입력의 크기 $n$에 대해서 알고리즘의 수행시간은 **아무리 늦어도** $f(n)$은 된다. ($f(n)$이 상한이다.)
- 수행시간이 $f(n)$보다 더 느릴 수는 없다는 말이다.
= Worst-case일 때, 이 정도 시간이면 된다.

##### Tight upper bound
길어야 $N$시간이면 되는 알고리즘은 $N^{2}$도 $N^{3}$도 만족하는 게 당연하다.
- 알고리즘의 특성을 표현하려면 Tight upper bound를 사용해야 함.
= Say “$2n$ is $O(n)$” instead of “$2n$ is $O(n^{2})$”

##### Use the simplest expression of the class
= Say “$3n + 5$ is $O(n)$” instead of “$3n + 5$ is $O(3n)$”

###### 예) $n2+10n\ {\in}\ O(n^2)$ ?
- 1) $n \geq 10$인 모든 정수 $n$에 대해서 $n^2+10n \leq 2n^2$ 이 성립한다. 그러므로, $c = 2, n_0 = 10$을 선택하면, “$Big \ O$”의 정의에 의해서 $n2+10n\ {\in}\ O(n^2)$이라고 결론 지을 수 있다.
###### $2n^{2}$과 $n^{2} + 10n$의 비교
![[Pasted image 20240425090745.png]]

## $\Omega$ 표기법
점근적 하한
##### 어떤 알고리즘의 시간복잡도가 $\Omega(f(n))$이라면 
- 입력의 크기 $n$에 대해서 알고리즘의 수행시간은 **아무리 빨라도** $f(n)$은 된다. *($f(n)$이 하한이다.)*
- 수행시간이 $f(n)$보다 더 빠를 수는 없다는 말이다.
= Best-case일 때, **최소한 이만한 시간은 걸린다.**
* 모든 정렬 알고리즘은 $\Omega(N)$. $N$개의 데이터를 정렬하는데 $N$개 모두를 읽지않고 정렬을 완료할 수는 없기 때문.


## $\Theta$ 표기법
정의: Asymptotic Tight Bound
- 복잡도 함수 $f(n)$에 대해서 $\Theta(f(n))=O(f(n)) \cap \Omega(f(n))$ 
- $\Theta(f(n))$은 다음을 만족하는 복잡도 함수 $g(n)$의 집합이다.

= $n \geq n_{0}$ 인 모든 정수 $n$에 대해서 $c \times f(n) \leq g(n) \leq d \times f(n)$ 이 성립하는 실수 $c > 0$와 $d > 0$, 음이 아닌 정수 $N$이 존재한다.

- 참고: $g(n)\ {\in}\ \Theta(f(n))$은 "$g(n)$은 $f(n)$의 차수(order)" 라고 한다.
- 예) $T(n) = \frac{n(n-1)}{2}$은 $O(n^2)$이면서 $\Omega(n^2)$이다.
   => $T(n) = \Theta(n^2)$ 
![[Pasted image 20240425094952.png]]

![[Pasted image 20240425095133.png]]

상한도 밝혀지고, 하한도 밝혀지면 $\Theta$라고 표현하고 그걸  $f(n)$의 차수라고 한다.

## 순환 알고리즘 (Recursion)
= 정의하려는 그 개념 자체를 정의 속에 포함
**종류**
- 직접 순환 : 함수가 직접 자기 자신을 호출
- 간접 순환 : 다른 제 3의 함수를 호출하고 그 함수가 다시 자신을 호출
**순환방식의 적용**
- 분할 정복 (divide and conquer) 특성을 가진 문제에 적합
- 어떤 복잡한 문제를 직접 바로 간단하게 풀 수 있는 작은 문제로 분할하여 해결하려는 방법. 
- 이 작고 간단한 문제는 원래의 문제와 그 성질이 같기 때문에 푸는 방법도 동일
**순환 함수의 명령문 골격**
- if (simplest case) then solve directly;
- else make a recursive call to a simler case;

1. 알고리즘 A를 받은 걸 분석을 해야 한다
2. $T_n$을 구한다
3. $O(n)$을 구한다
 - 1. $T_n \leq c \cdot f(n)$
 - 2. pick $c,n_0$
 - 3. 검증
### 순환 함수의 예
#### 이진탐색
정의: 주어진 탐색키로 key가 저장된 위치(index) 찾아내는 방법
- `key == a[mid]` : 탐색 성공, return mid
- `key < a[mid]`  : `a[mid]`의 왼편에 대해 탐색시작
- `key > a[mid]`  : `a[mid]`의 오른편에 대해 탐색시작
###### 순환함수의 표현 
`BinarySearch(a[], key, left, right) 
`// a[mid] = key인 인덱스 mid를 반환 
`  if (left <= right) then { 
`    mid ← (left + right) / 2; 
`    case { 
`      key = a[mid] : return (mid); 
`      key < a[mid] : return (BinarySearch(a, key, left, mid-1));
`      key > a[mid] : return (BinarySearch(a, key, mid+1, right));
`    } 
`  } 
`  else return -1; // key 값이 존재하지 않음 
`end BinarySearch()`

재귀호출을 하고 있다.
binary search를 모두 $T$로 치환
배열의 왼쪽이 left 오른쪽이 right
$n$개의 입력이라면 $n$까지 크기

1. 입력이 $n$일 때 걸리는 시간 $T_n$
배열의 중간이 mid가 되고
그러면 $T_{\frac{n}{2}}$ 2개가 된다
둘 중에 하나만 실행이 된다 
$T$로 변하지 않는 모든 것들을 유닛하게 1로 본다 (변수 선언, 논리연산 등등)
그러면 여기까진 $T_n = T_{\frac{n}{2}} + 1$
들어가보면 또 $T_{\frac{n}{2}} = T_{\frac{n}{2^2}} + 1$
$T_{n} = (((T_\frac{n}{2^3}+1) + 1) + 1)$
$T_n = T_\frac{n}{2^3} + 3$
2. i로 일반화
$T_n = T_\frac{n}{2^i} + i$
$\frac{n}{2^i} = 1$이 될 때까지
$n = 2^i$
$i = \log_{2}{n}$
대입하면 
$T_n = T_1 + \log_{2}{n}$ 
$=\log_{2}{n}+ 1$이 된다
$O(\log n)$

### 출처(참고문헌)
-

### 연결문서
-